{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP25MxQRAGa0yRKRPW6eZ7d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeff-ai-ml/genai/blob/main/RAG_PDF_Read_Summary_Using_Mistral_ChromaDB_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8HpdQx8fNlal"
      },
      "outputs": [],
      "source": [
        "# === Install Required Packages ==="
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# === Install Required Packages ==="
      ],
      "metadata": {
        "id": "4AtH-Cq0NtHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-mistralai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRk3U7WRYlya",
        "outputId": "9dcb186c-6a98-4f21-b72d-db52a1b05482"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-mistralai\n",
            "  Downloading langchain_mistralai-0.2.11-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.3.70)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.21.2)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse<1,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.4.1)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (2.11.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain-mistralai) (0.16.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (0.4.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-mistralai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-mistralai) (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15.1->langchain-mistralai) (0.33.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2025.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (1.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-mistralai) (0.23.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.2->langchain-mistralai) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2.5.0)\n",
            "Downloading langchain_mistralai-0.2.11-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: langchain-mistralai\n",
            "Successfully installed langchain-mistralai-0.2.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate\n"
      ],
      "metadata": {
        "id": "j8jLNlKXNqIP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Mistral LLM"
      ],
      "metadata": {
        "id": "rMLEzqRvOaps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mistralai import ChatMistralAI # For Mistral AI API\n",
        "# OR if using a local/hosted Mistral model via Langchain's generic LLM interface:\n",
        "# from langchain_community.llms import Ollama # Example for local Ollama setup\n",
        "# from langchain_community.chat_models import ChatOllama # Example for chat models with Ollama"
      ],
      "metadata": {
        "id": "hkW-UvZkOdJN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# === Set Paths ==="
      ],
      "metadata": {
        "id": "rfzRfnd9Ol2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHROMA_PATH = \"Chroma\"\n",
        "DOC_PATH = \"/content/sample_data/20220202_alphabet_10K.pdf\""
      ],
      "metadata": {
        "id": "05wZHShAOoIF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# === Step 1: Load and Chunk PDF ==="
      ],
      "metadata": {
        "id": "l3Are-NbPV9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load your pdf doc\n",
        "loader = PyPDFLoader(DOC_PATH)\n",
        "pages = loader.load()\n",
        "\n"
      ],
      "metadata": {
        "id": "TiJNpD8KPYFZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the doc into smaller chunks i.e. chunk_size=500\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "BuDi5XtmPfeJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# === Step 2: Embeddings (HuggingFace) ==="
      ],
      "metadata": {
        "id": "q1J1en5EPiTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get Embedding model (keep as is, as you specified no change to vector DB)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4dpuc4k7Pkcx"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# === Step 3: Store in Chroma Vector DB ==="
      ],
      "metadata": {
        "id": "zwT7-pI3QJF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embed the chunks as vectors and load them into the database.\n",
        "db_chroma = Chroma.from_documents(chunks, embeddings, persist_directory=CHROMA_PATH)"
      ],
      "metadata": {
        "id": "I08FLRsrQLFk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# === Step 4: Define User Query ==="
      ],
      "metadata": {
        "id": "NJYvo9izQWd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is an example of a user question (query)\n",
        "query = 'Summarize the 20220202_alphabet_10K document'"
      ],
      "metadata": {
        "id": "i5jzbu3AQXMb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# === Step 5: Retrieve Similar Chunks ==="
      ],
      "metadata": {
        "id": "-L8nnVU6Qem-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve context - top 5 most relevant (closest) chunks to the query vector\n",
        "docs_chroma = db_chroma.similarity_search_with_score(query, k=5)"
      ],
      "metadata": {
        "id": "JO8ni0GVQfyP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate an answer based on given user query and retrieved context information\n",
        "context_text = \"\\n\\n\".join([doc.page_content for doc, _score in docs_chroma])"
      ],
      "metadata": {
        "id": "XBc1awPqQuRG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# === Step 6: Prompt Template ==="
      ],
      "metadata": {
        "id": "XVN_T1QURFZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# you can use a prompt template\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Answer the question based only on the following context:\n",
        "{context}\n",
        "Answer the question based on the above context: {question}.\n",
        "Provide a detailed answer.\n",
        "Don’t justify your answers.\n",
        "Don’t give information not mentioned in the CONTEXT INFORMATION.\n",
        "Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nEy7_W7KRGTW"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# === Step 7 - Set Mistral as LLM for RAG ==="
      ],
      "metadata": {
        "id": "y1OJTczKbvke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "-ObDjy5tbY1T"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the Mistral API key from Colab Secrets\n",
        "try:\n",
        "    # 1. Retrieve the secret from Colab's userdata.\n",
        "    MISTRAL_API_KEY = userdata.get(\"MISTRAL_API_KEY\")\n",
        "    # 2. Set it as an environment variable for the current session.\n",
        "    os.environ[\"MISTRAL_API_KEY\"] = MISTRAL_API_KEY\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving MISTRAL_API_KEY from Colab Secrets: {e}\")\n",
        "    print(\"Please ensure you have set 'MISTRAL_API_KEY' in Colab Secrets and granted notebook access.\")\n",
        "    exit() # Stop execution if the key isn't found, as the LLM won't work."
      ],
      "metadata": {
        "id": "KXMkLE6GbgiL"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Mistral LLM"
      ],
      "metadata": {
        "id": "8nFb2JpWdBe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# If using Mistral AI's official API:\n",
        "model = ChatMistralAI(model=\"mistral-medium\", temperature=0.7) # You can choose \"mistral-tiny\", \"mistral-small\", \"mistral-medium\""
      ],
      "metadata": {
        "id": "hW0JNMqXRMgH"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load retrieved context and user query in the prompt template\n",
        "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "prompt = prompt_template.format(context=context_text, question=query)"
      ],
      "metadata": {
        "id": "ABFvfJejaR1H"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call LLM model to generate the answer based on the given context and query\n",
        "response_text = model.invoke(prompt) # Use .invoke() for ChatModels in Langchain\n",
        "print(response_text.content) # Access the content of the response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRhTR7VGaRxs",
        "outputId": "7faa0940-50c9-41b9-b590-5afce61206cd"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The document is Alphabet Inc.'s Form 10-K for the fiscal year ended December 31, 2021. It includes a table of contents listing key sections such as:\n",
            "\n",
            "**PART I:**\n",
            "- **Item 1. Business** (Page 4)\n",
            "- **Item 1A. Risk Factors** (Page 10)\n",
            "- **Item 1B. Unresolved Staff Comments** (Page 24)\n",
            "- **Item 2. Properties** (Page 24)\n",
            "- **Item 3. Legal Proceedings** (Page 24)\n",
            "- **Item 4. Mine Safety Disclosures** (Page 24)\n",
            "\n",
            "**PART II:**\n",
            "- **Item 5. Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities** (Page 25)\n",
            "- **Item 6. [Reserved]** (Page 27)\n",
            "\n",
            "Additional sections include references to stock plans:\n",
            "- **10.06.1**: Alphabet Inc. Amended and Restated 2012 Stock Plan - Form of Alphabet Restricted Stock Unit Agreement (Annual Report on Form 10-K, February 4, 2020).\n",
            "- **10.06.2**: Alphabet Inc. Amended and Restated 2012 Stock Plan - Performance Stock Unit Agreement (Annual Report on Form 10-K, February 4, 2020).\n",
            "- **10.07**: Alphabet Inc. 2021 Stock Plan (Current Report on Form 8-K, June 4, 2021).\n",
            "\n",
            "The document notes that discussions of 2019 results are omitted where redundant to the 2020 Annual Report on Form 10-K. It also provides an overview of Alphabet’s structure, highlighting Google as its largest business, divided into Google Services and Google Cloud, with all non-Google businesses categorized as Other Bets.\n"
          ]
        }
      ]
    }
  ]
}